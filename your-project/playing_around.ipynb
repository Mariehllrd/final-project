{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import glasses img\n",
    "glasses = cv2.imread('imageedit_1_9641209111.png', -1)\n",
    "\n",
    "# Create the mask for the glasses\n",
    "glasses_gray = cv2.cvtColor(glasses, cv2.COLOR_BGR2GRAY)\n",
    "ret, orig_mask = cv2.threshold(glasses_gray, 10, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask\n",
    "orig_mask_inv = cv2.bitwise_not(orig_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses = glasses[:,:,0:3]\n",
    "orig_height, orig_width = glasses.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture video feed\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    " \n",
    "    # Create greyscale image from the video feed\n",
    "    gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Detect faces in input video stream\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    " \n",
    "   # Iterate over each face found\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    " \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    " \n",
    "        # Detect eyes within the region bounded by each face (the ROI)\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    " \n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)\n",
    " \n",
    "            # The glasses should be three times the width of the eyes\n",
    "            glasses_width =  3 * ew\n",
    "            glasses_height = glasses_width * orig_height / orig_width\n",
    " \n",
    "            # Center the mustache on the bottom of the nose\n",
    "            x1 = ex - (glasses_width / 4)\n",
    "            x2 = ex + ew + (glasses_width / 4)\n",
    "            y1 = ey + eh - (glasses_height / 2)\n",
    "            y2 = ey + eh + (glasses_height / 2)\n",
    " \n",
    "            # Check for clipping\n",
    "            if x1 < 0:\n",
    "                x1 = 0\n",
    "            if y1 < 0:\n",
    "                y1 = 0\n",
    "            if x2 > w:\n",
    "                x2 = w\n",
    "            if y2 > h:\n",
    "                y2 = h\n",
    " \n",
    "            # Re-calculate the width and height of the mustache image\n",
    "            glasses_width = x2 - x1\n",
    "            glasses_height = y2 - y1\n",
    " \n",
    "            # Re-size the original image and the masks to the mustache sizes\n",
    "            # calcualted above\n",
    "            dsize = (int(glasses_width),int(glasses_height))\n",
    "            \n",
    "            glasses = cv2.resize(glasses, dsize, interpolation = cv2.INTER_AREA)\n",
    "            mask = cv2.resize(orig_mask, dsize, interpolation = cv2.INTER_AREA)\n",
    "            mask_inv = cv2.resize(orig_mask_inv, dsize, interpolation = cv2.INTER_AREA)\n",
    " \n",
    "            # take ROI for mustache from background equal to size of mustache image\n",
    "            roi = roi_color[int(y1):int(y2), int(x1):int(x2)]\n",
    " \n",
    "            # roi_bg contains the original image only where the mustache is not\n",
    "            # in the region that is the size of the mustache.\n",
    "            roi_bg = cv2.bitwise_and(roi, roi, mask = mask_inv)\n",
    " \n",
    "            # roi_fg contains the image of the mustache only where the mustache is\n",
    "            roi_fg = cv2.bitwise_and(glasses, glasses, mask = mask)\n",
    " \n",
    "            # join the roi_bg and roi_fg\n",
    "            dst = cv2.add(roi_bg,roi_fg)\n",
    " \n",
    "            # place the joined image, saved to dst back over the original image\n",
    "            roi_color[int(y1):int(y2), int(x1):int(x2)] = dst\n",
    " \n",
    "            break\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    " \n",
    "    # press any key to exit\n",
    "    # NOTE;  x86 systems may need to remove: \" 0xFF == ord('q')\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
